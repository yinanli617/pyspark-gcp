apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: write-parquet
  namespace: yinanli
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: docker.io/yinanli617/pyspark-operator:v3.1.1
  imagePullPolicy: Always
  mainApplicationFile: https://raw.githubusercontent.com/yinanli617/test/main/write-parquet.py
  sparkVersion: "3.1.1"
  hadoopConf:
    "fs.gs.project.id": "kubeflow-yli"
    "fs.gs.system.bucket": "pyspark-yli"
    "google.cloud.auth.service.account.enable": "true"
    "google.cloud.auth.service.account.json.keyfile": "/mnt/secrets/spark-sa.json"
  driver:
    cores: 1
    labels:
      version: 3.1.1
    secrets:
      - name: "spark-sa"
        path: "/mnt/secrets"
        secretType: GCPServiceAccount
    envVars:
      GCS_PROJECT_ID: kubeflow-yli
    serviceAccount: spark-sa
  executor:
    instances: 2
    cores: 1
    labels:
      version: 3.1.1
    memory: "512m"
    secrets:
      - name: "spark-sa"
        path: "/mnt/secrets"
        secretType: GCPServiceAccount
    envVars:
      GCS_PROJECT_ID: kubeflow-yli
